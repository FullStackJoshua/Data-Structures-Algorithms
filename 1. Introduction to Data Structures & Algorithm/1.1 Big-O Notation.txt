# Big O notation is a way to describe the efficiency of an algorithm, specifically how its runtime or space 
# requirements grow as the size of the input increases. It helps you understand the worst-case scenario for 
# how long an algorithm will take to run or how much memory it will use.

Key Points:
Focus on the Largest Term: Big O notation ignores constants and lower-order terms because, for large inputs, 
they have little impact on the overall efficiency.

Common Big O Notations:

O(1): Constant time. The algorithm takes the same amount of time regardless of input size.
Example: Accessing an element in an array by its index.

O(log n): Logarithmic time. The algorithm’s runtime increases slowly as the input size grows.
Example: Binary search.

O(n): Linear time. The runtime grows directly proportional to the input size.
Example: Looping through an array.

O(n log n): Linearithmic time. A bit slower than linear, but more efficient than quadratic time.
Example: Efficient sorting algorithms like mergesort and quicksort.

O(n²): Quadratic time. The runtime grows proportionally to the square of the input size.
Example: Nested loops over an array.

O(2ⁿ): Exponential time. The runtime doubles with each additional element in the input.
Example: Solving the Traveling Salesman Problem using brute force.